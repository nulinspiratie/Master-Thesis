%!TEX root = ../thesis.tex
\input{noise.tex}

\chapter{Duplexer characterization}
  \section{Duplexer isolation}
  \label{ch:Duplexer isolation}

\chapter{Chip characterization}
  \section{qubit coherence times versus frequency}
  \section{Muxmon1 coherence times}
    \label{sec:Muxmon1 coherence times}
  \section{Muxmon0 resonator buses}
    \label{sec:Resonator buses}

\chapter{Additional notes}
  \section{Qubit characterization}
    \subsection{Part I: Continuous-wave measurements}
      \subsubsection{Powersweep}
        \begin{itemize}
          \item If the resonator seems to disappear after the transition from dressed frequency to bare frequency (or vice versa), this is likely due to the qubit being extremely close to the resonator, and so the frequency shift is large.
        \end{itemize}
      \subsection{Finding the qubit sweet-spot using a one-dimensional scan}
        \label{Finding the qubit sweet-spot using a one-dimensional scan}
        \begin{figure}[tb]
          \centering
          \includegraphics[width=.6\linewidth]{../Figures/Qubit characterization/Resonator vs DAC linecut.png}
          \caption{Fixed frequency transmission versus DAC current. The frequency is chosen to be slightly below the resonator frequency found when the DAC current is set to zero. The symmetry point in the linecut corresponds to the sweet-spot of the ancilla qubit.}
          \label{fig:resonator vs dac linecut}
        \end{figure}

        As explained in Section~\ref{Scan for qubit sweet-spots}, the sweet-spot of a qubit can be found by performing a series of resonator scans while varying the DAC current. There is however, a faster approach for finding the qubit sweet-spot, at the cost of providing less information. This is done by choosing a fixed frequency close to the resonator's frequency $\wres$ (preferrably slightly below, where the transmission slope is steepest). By measuring the amount of transmission as the DAC voltage is being varied, one obtains essentially a line-cut of the 2D scan. The idea this measurement is that if the qubit frequency $\fqub$ decreases, so does resonator frequency, resulting in a decrease in transmission (closer to $\wres$). Likewise, if the qubit frequency $\wqub$ increases, so does the resonator frequency, resulting in an increase in transmission (further away from $\wres$).

        At the qubit's sweet-spot, the resonator's frequency $\wres$ is at a maximum, and so the transmission should also be at a maximum. Furthermore, because the qubit frequency is symmetric with respect to its sweet-spot, so should the transmission. The sweet-spot can therefore be determined by finding the symmetric point in the transmission. In Figure~\ref{fig:resonator vs dac linecut} one such linecut is shown. The transmission is clearly symmetric, and the symmetric point is equal to the qubit sweet-spot.

        If the resonator's frequency $\wres$ shifts by a large amount in the course of this measurement, it becomes harder to determine where the sweet-spot is (although even then often it can still be discerned). Nevertheless, this method is considerably faster than performing a full two-dimensional scan of frequency versus DAC voltage, and in most cases does provide sufficient information to determine the sweet-spot.


      \subsubsection{Spectroscopy}
        \begin{itemize}
          \item If the deviation in transmission becomes less due to more detuning, increasing the power can also increase the contrast.
        \end{itemize}
    \subsection{Part I: Time-domain measurements}
      \subsubsection{AllXY}
        \label{ssec:AllXY}
        \textbf{TODO:}
        \begin{itemize}
          \item Table of AllXY pulses
        \end{itemize}
  \section{Randomized benchmarking}
    \subsection{Clifford gate decomposition}
      \label{ssec:Clifford gate decomposition}

      \begin{figure}[tb]
        \centering
        \includegraphics[width=\textwidth]{../Figures/Clifford decomposition.png}
        \caption{Decomposition of all $24$ Cliffords into X and Y rotations}
        \label{fig:Clifford decomposition}
      \end{figure}
      \textbf{TODO:} Cite

    \subsection{Individual randomized benchmarking measurements}
      \label{ssec:Individual randomized benchmarking measurements}

    \subsection{Determining population in three states}
      \label{ssec:Determining population in three states}
      If there were no leakage present during randomized benchmarking, the full information about the state populations can be extracted from the randomized benchmarking results. However, if leakage to the second-excited state is present, the full information about the populations of the three states can be extracted using two versions of randomized benchmarking, one without a final pi pulse, and one with a final pi pulse. The final pi pulse swaps the populations in the ground and excited state. We assume that the population of the second excited-state remains unaffected by this single final pulse.

      Using these two randomized benchmarking sequences, two different signals $S_0$ and $S_1$ are measured, corresponding to a measurement without a final pi pulse, and a measurement with a final pi pulse, respectively. This leads to the following three equations:

      \begin{align}
        p_0 V_0 + p_1 V_1 + p_2 V_2 = & S_0 \notag\\
        p_1 V_1 + p_0 V_1 + p_2 V_2 = & S_1 \notag\\
        p_0 + p_1 + p_2 = &   1
        \label{eq:three populations equations App}
      \end{align}

      where $p_i$ corresponds to the final population in state $\ket{i}$, and $V_i$ is the signal of state $\ket{i}$.  Filling in $p_2 = 1 - p_0 - p_1$ into the first two equations of \ref{eq:three populations equations App}, we are left with the following set of equations:

      \begin{align}
        \begin{bmatrix}
          V_0 - V_2 & V_1 - V_2 \\
          V_1 - V_2 & V_0 - V_2
        \end{bmatrix}
        \begin{bmatrix}
          p_0 \\
          p_1
        \end{bmatrix}
        =
        \begin{bmatrix}
          S_0 - V_2 \\
          S_1 - V_2
        \end{bmatrix}
      \end{align}

      This set of equations can be easily solved by matrix inversion, resulting in the following three populations:

      \begin{align}
        \begin{bmatrix}
          p_0 \\
          p_1
        \end{bmatrix}
        = &
        \left((V_0-V_2)^2 - (V_1 - V_2)^2\right)^{-1}
        \begin{bmatrix}
          V_0 - V_2 & -V_1 + V_2 \\
          -V_1 + V_2 & V_0 + V_2
        \end{bmatrix}
        \begin{bmatrix}
          S_0 - V_2 \\
          S_1 - V_2
        \end{bmatrix} \notag\\
        p_2 = & 1 - p_0 - p_1
        \label{eq:RB populations using final pi}
      \end{align}
      If one has knowledge of all thee signals $V_0$, $V_1$ and $V_2$ (see Section~\ref{ssec:Second excited-state} for information on measuring $V_2$), the three populations can be obtained using \ref{eq:RB populations using final pi}.
    \section{$5$ primitives decomposition}
      \label{sec:5 primitives decomposition}

\chapter{Algorithms}
  \section{Tracked spectroscopy}
  \label{sec:Tracked spectroscopy}
    \begin{itemize}
      \item Information may lie in amplitude or in phase, or in a combination of the two. For most accurate measure, calculate distance from ground state.
    \end{itemize}
  \section{Peak finding}
    \subsection{Normal peak finder}
    \subsection{Derivative peak finder}
  \section{Compiled randomized benchmarking}
    \label{sec:compiled randomized benchmarking algorithm}
    \subsection{Finding the optimal gate sequence}
      In compiled randomized benchmarking each set of Cliffords is compiled such that the total number of pulses sent is as small as possible. This is done by comparing all the possible decompositions for each Clifford in the set of Cliffords with each other, and determining the combination that results in the least amount of total pulses.

      Given a tuple of Cliffords $\left(C_{\alpha_1}^1, \dots, C_{\alpha_n}^n\right)$, where $n$ is the number of qubits and $\alpha_i$ is the Clifford number for qubit $i$, a particular decomposition of the Cliffords is given by $\left(\left( G_1^1, ..., G_{m_1}^1 \right) , ..., \left(G_1^n, ..., G_{m_n}^n\right)\right)$, where $m_i$ is the number of gates in the decomposition of Clifford $C_{\alpha_i}^i$, and $G_j^i$ is gate $j$ of the Clifford decomposition of $C_i$. The algorithm used for finding the minimum number of gates for a particular tuple of Clifford decompositions is a recursive algorithm. The algorithm determines all possible ways in which the gates can be ordered, and finally chooses the sequence having the smallest length.

      To explain this algorithm, let us denote $\bm{\beta}=\left(\beta_1, \dots, \beta_n\right)$ as the indices of the next possible gates. The corresponding gates are given by $\bm{G_\bm{\beta}}=\left( G_{\beta_1}^1, \dots, G_{\beta_n}^n \right)$. If the indices where $\beta_i=m_i + 1$, there is no next gate, and so $G_{\beta_i}$ does not exist and should not be added to $\bm{G_\bm{\beta}}$.

      \begin{enumerate}
        \item Start with an empty sequence of gates $G_\text{seq}$ and gate indices $\bm{\beta} = \left(\beta_1, ..., \beta_n\right) = \left(1, ..., 1\right)$
        \item Determine the set of distinct gates in $G_{\bm{\beta}}$.
        \item For each gate $g$ in the set of distinct gates perform the following steps:
        \begin{enumerate}
          \item Append $g$ to $G_\text{seq}$.
          \item Determine all indices $i$ for which the next gate $G_{\beta_i}^i$ equals $g$.
          \item Copy gate indices $\bm{\beta}$ to $\bm{\beta}^\text{new}=\left(\beta_1^\text{new}, ..., \beta_n^\text{new}\right)=\left(\beta_1, ..., \beta_n\right)$.
          \item For all indices $i$ for which $G_{\beta_i}^i=g$, increase the gate index $\beta_i^\text{new} = \beta_i+1$.
          \item Go to step two using the new gate indices $\bm{\beta}^\text{new}$.
        \end{enumerate}
        \item If $G_{\bm{\beta}}$ is empty, then $G_\text{seq}$ is a particular sequence of pulses that would result in all Cliffords being applied.
        \item When all possible sequences are combined, choose the sequence with the minimum number of gates in $G_\text{seq}$
      \end{enumerate}

      This algorithm determines the least amount of gates necessary to perform all Cliffords in one particular tuple of decompositions. However, each Clifford has on average $38$ different decompositions, and so for $n$ qubits the total decomposition combinations is approximately$38^n$, meaning this algorithm would have to be repeated $38^n$ times to find the global minimum number of pulses to perform all Cliffords. And in fact this would only determine the optimal compilation for one particular set of Cliffords; to find the average gates per Clifford tuple one would have to perform this on all possible combinations of Cliffords and then determine the average gates per Clifford tuple. This problem therefore scales exponentially with the number of qubits, and would seem impossible for as few as $n=3$ qubits, as it would require $24^3*38^3=7.6*10^8$ different decomposition combinations. Nevertheless the average gates per Clifford has been calculated exactly for up to $n=5$ qubits. This has been done using several optimization methods, which will be discussed below.

    \subsection{Optimizing the gate compilation algorithm}
      \label{Optimizing the gate compilation algorithm}
      Determining the average gates per Clifford tuple for $n=5$ qubits would initially result in $6.3*10^{14}$ different combinations of Clifford decompositions. For each of these combinations the algorithm must find the least amount of gates necessary to perform all gates in that particular set of Clifford decompositions. It is clear that this is computationally not viable. Luckily several optimizations can be performed which can drastically reduce this number by many orders of magnitude. These optimizations will be discussed in this section.

      The first and simplest optimization is from the simple observation that the optimal gate compilation for a certain tuple of Cliffords $\left(C_{\alpha_1}^1, \dots, C_{\alpha_n}^n\right)$ is the same as any permutation of those Cliffords. Therefore we only have to determine the optimal compilations for the tuples $\left(C_{\beta_1}^1, \dots, C_{\beta_n}^n\right)$ where $\beta_1 \leq \beta_2 \leq \dots \leq \beta_n$. This already reduces the amount of calculations by an exponential amount (a factor $81$ times less computations when $n=5$.

      The second optimization is to keep track of the minimum number of gates so far found that can compile a given tuple of Cliffords. At each stage of the algorith it checks if the gates that are so far in $G_\text{seq}$ plus all the distinct gates left in $G_{\bm{\beta}}$ is equal to or greater than the minimum number of gates found so far. If this is the case, it will know that it cannot find a better combination of gates using the sequence $G_\text{seq}$. It can therefore stop this sequence and start with the next sequence. The minimum number of gates can initially be placed at $5$ gates, as the $5$ primitives method proves that there is always a decomposition of an arbitrary number of Cliffords into $5$ gates. This optimization places an upper bound on the number of gates, and results in a massive decrease in computation time. This is especially the case because as the minimum number of gates decreases, so does the frequency at which the algorithm stops its current sequence increase.

      The third optimization relies on the fact that it is more likely that decompositions with fewer gates result in an optimal gate compilation. Therefore the decompositions of all Cliffords have been arranged in ascending number of gates. When comparing the decompositions of the Cliffords the first decompositions compared are those with the fewest gates. The probability of finding the optimal gate compilation is therefore high, and even if it did not find the optimal gate compilation, it is likely that the minimum gate length found so far will be low. This optimization is especially effective when combined with the second optimization.

      The fourth optimization places a lower bound on the number of gates. For a given tuple of Cliffords $\left(C_{\alpha_1}^1, \dots, C_{\alpha_n}^n\right)$, the lower bound is found by looking at the optimal lengths previously found for all $n-1$ Clifford subsets. This requires knowledge of the lengths of all the $n-1$ Cliffords. Since the length of the tuple of $n$ Cliffords can never be less than any of the lengths of the $n-1$ Clifford subsets, the maximum of these lengths therefore places a lower bound on the optimal number of gates. This means that if during the algorithm ever finds one sequence of gates for any tuple of decompositions whose length is equal to this lower bound, it will know it has found the optimal gate compilation for the tuple of Cliffords, and may abort all further search. This is in contrast to the second optimization, where an upper bound was found, in which case only the particular sequence of gates could be aborted. As the number of qubits increases, it becomes more and more likely that the lower bound is equal to five. In this case the lower bound is equal to the upper bound set by the $5$ primitives method, and so it can immediately be concluded that the optimal gate compilation is the $5$ primitives method. This optimization that places a lower bound is probably the best of all optimizations used, and results in a massive gain in computation time, by many orders of magnitude.

      The fifth optimization is the most complicated optimization, and is based on separating all decompositions with three gates or less from those composed of four gates. In this optimization first all combinations are tested using only decompositions with three or less gates. This greatly reduces the average number of decompositions per Clifford, from $38$ to $7$. Especially as the number of qubits increases, this results in drastically less comparisons in total. Now it is not always the case that the minimum number of gates is found using only up to three gates per decomposition: sometimes the optimal gate compilation requires one of the decompositions to have four gates. However, we only need to include four gate decompositions when the lower bound is four or less and when the minimum gate compilation found using only three gates or less is equal to five or more. Only in this case could there be a four gate decomposition that could outperform gate decompositions with only three gates or less. We furthermore know that if there is such a four gate decomposition that results in the optimal gate compilation, its length must be equal to four, as the $5$ primitives method places the upper bound at $5$ gates. We therefore also know that only one Clifford can have a four gate decomposition, and all other Cliffords must be subsets of these four gates. We can therefore simply loop over each of the four gate decompositions, and test whether all other Cliffords are subsets of these four gates. This changes the comparison from scaling exponential with the number of qubits to scaling linear with the number of qubits.

      \begin{table}
        \begin{tabular}{l c}
          \toprule
          number of qubits  & average gates per Clifford \\
          \midrule
          1 & 1.875 \\
          2 & 2.925 \\
          3 & 3.521 \\
          4 & 3.874 \\
          5 & 4.137 \\
          \bottomrule
        \end{tabular}
        \caption{The average gates per Clifford after compilation. Values up to n=5 have been calculated exact, while values starting from n=6 have been determined using random sampling.}
        \label{tab:gates per Clifford}
      \end{table}


      \begin{table}
        \begin{tabular}{l c c c c c c c c c c }
          number of qubits & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
          gates per Clifford & 1.875 & 2.925 & 3.521 & 3.874 & 4.137 & 4.380 (12)& 4.570 (15)& 4.721 (10)& 4.808 (14)& 4.857 (24) \\
        \end{tabular}
        \caption{The average gates per Clifford after compilation. Values up to n=5 have been calculated exact, while values starting from n=6 have been determined using random sampling.}
        % \label{tab:gates per Clifford}
      \end{table}

      Using these $5$ optimizations the average gates per Clifford tuple has been calculated exactly for $n=5$ qubits within two hours. Furthermore, the average gates per Clifford has been approximated for up to $n=10$ Cliffords using random sampling. The results are shown in Table~\ref{tab:gates per Clifford}.

    \begin{itemize}
      \item Change set to the correct term
      \item Talk about constraints: Single pulse sequence, markers
    \end{itemize}